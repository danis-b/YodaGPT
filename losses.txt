#epoch train_loss val_loss
0 4.3512864112854 4.351904392242432
1 2.7307944297790527 2.6334846019744873
2 2.388455629348755 2.2864937782287598
3 2.2708616256713867 2.158681631088257
4 2.037123441696167 1.915919303894043
5 1.8241209983825684 1.709348440170288
6 1.6727688312530518 1.5818696022033691
7 1.5695571899414062 1.5164772272109985
8 1.4939239025115967 1.4531550407409668
9 1.443414568901062 1.4301137924194336
10 1.3961840867996216 1.4069350957870483
11 1.35599684715271 1.3766021728515625
12 1.3241913318634033 1.354684591293335
13 1.29938542842865 1.350529432296753
14 1.275558352470398 1.3418548107147217
15 1.2574797868728638 1.3253636360168457
16 1.240485429763794 1.328007698059082
17 1.2265568971633911 1.3200013637542725
18 1.2078063488006592 1.306355595588684
19 1.1946873664855957 1.303165316581726
20 1.1852835416793823 1.303625226020813
21 1.1733098030090332 1.2993084192276
22 1.1627262830734253 1.2871441841125488
23 1.1479802131652832 1.2972270250320435
24 1.1421316862106323 1.2869415283203125
25 1.1294922828674316 1.2862613201141357
26 1.122639775276184 1.2886910438537598
27 1.114488959312439 1.289076566696167
28 1.1081007719039917 1.2828423976898193
29 1.0987945795059204 1.2685346603393555
30 1.0956898927688599 1.279512643814087
31 1.0875084400177002 1.2723983526229858
32 1.0780327320098877 1.2774064540863037
33 1.0706901550292969 1.2732599973678589
34 1.0665194988250732 1.267574429512024
35 1.0593279600143433 1.2734228372573853
36 1.058578372001648 1.2789655923843384
37 1.0459144115447998 1.2725485563278198
38 1.0445363521575928 1.2671082019805908
39 1.0366979837417603 1.2690496444702148
